# QMD 语义搜索引擎完全指南

## 概述

**QMD**（Quantum Memory Daemon）是一个独立的本地语义搜索引擎，用于在 Markdown 文件中实现智能搜索。它结合 BM25 全文搜索、向量语义搜索和 LLM 重排序，所有计算都在本地完成，无需联网。

**核心特性：**
- 语义理解：基于向量嵌入理解查询意图
- 本地优先：无需 API Key，保护隐私
- 独立工具：可脱离 OpenClaw 单独使用
- 开源免费：GitHub 开源项目

---

## 1. 安装指南

### 1.1 系统要求

| 项目 | 要求 |
|------|------|
| **运行时** | Bun ≥ 1.0.0 |
| **架构** | x64 / ARM64 (aarch64) |
| **存储** | 模型文件约 1.5 GB |
| **内存** | 建议 4GB+ |

### 1.2 从 GitHub 安装

**标准安装（x64）：**
```bash
bun install -g https://github.com/tobi/qmd
```

**ARM64 特别说明：**
在 ARM64 架构（如 Apple Silicon、Jetson、树莓派）上，安装时需要编译原生模块：

```bash
# 安装过程会自动编译 node-llama-cpp
bun install -g https://github.com/tobi/qmd

# 编译耗时较长（10-30 分钟，取决于硬件）
# 如果使用 CUDA，会编译 GPU 加速版本
```

**编译依赖：**
- C++ 编译器（g++ / clang）
- CMake ≥ 3.14
- CUDA Toolkit（可选，用于 GPU 加速）
- Python 3（用于 node-gyp）

### 1.3 验证安装

```bash
qmd --version
```

**输出示例：**
```
Index: /home/claw/.cache/qmd/index.sqlite
Models:
  - Embedding: embeddinggemma-300M-Q8_0
  - Reranking: qwen3-reranker-0.6b-q8_0
  - Generation: Qwen3-0.6B-Q8_0
```

### 1.4 首次运行（模型下载）

首次执行 QMD 命令时，会自动从 HuggingFace 下载模型：

```bash
qmd status
```

**下载的模型文件：**

| 模型 | 文件 | 大小 | 用途 |
|------|------|------|------|
| Embedding | `embeddinggemma-300M-Q8_0.gguf` | ~313 MB | 生成文本向量 |
| Query Expansion | `qmd-query-expansion-1.7B-q4_k_m.gguf` | ~1.2 GB | 查询扩展 |
| Reranker | `qwen3-reranker-0.6b-q8_0.gguf` | ~400 MB | 结果重排序 |

**模型存储位置：**
```
~/.cache/qmd/models/
```

**注意：** 首次下载模型需要良好网络连接，总大小约 1.5-2 GB。

---

## 2. 配置详解

QMD 与 OpenClaw 集成时需要两层配置：

### 2.1 第一层：QMD 服务配置（`memory`）

在 `~/.openclaw/openclaw.json` 中配置 QMD 服务本身：

```json
{
  "memory": {
    "backend": "qmd",
    "qmd": {
      "command": "/home/claw/.bun/bin/qmd",
      "includeDefaultMemory": false,
      "paths": [
        {
          "path": "/home/claw/.openclaw/workspace",
          "name": "workspace",
          "pattern": "**/*.md,!memory/**/*.md"
        },
        {
          "path": "/home/claw/.openclaw/workspace/memory",
          "name": "memory",
          "pattern": "**/*.md"
        }
      ],
      "update": {
        "interval": "5m",
        "debounceMs": 15000,
        "onBoot": true
      },
      "limits": {
        "maxResults": 6,
        "maxSnippetChars": 700,
        "timeoutMs": 4000
      }
    }
  }
}
```

**配置项说明：**

| 配置项 | 说明 |
|--------|------|
| `command` | QMD 可执行文件路径 |
| `includeDefaultMemory` | 是否使用默认记忆集合（建议 false） |
| `paths` | 搜索集合列表 |
| `pattern` | 文件匹配模式，`!` 表示排除 |
| `interval` | 自动更新索引间隔 |
| `onBoot` | 启动时是否更新索引 |
| `limits` | 搜索结果限制 |

### 2.2 第二层：Agent 搜索配置（`memorySearch`）

在 `agents.defaults` 中配置 OpenClaw Agent 如何调用 QMD：

```json
{
  "agents": {
    "defaults": {
      "memorySearch": {
        "enabled": true,
        "extraPaths": [
          "/home/claw/.openclaw/workspace"
        ],
        "provider": "local",
        "fallback": "none",
        "local": {
          "modelCacheDir": "/home/claw/.cache/qmd/models"
        }
      }
    }
  }
}
```

**配置项说明：**

| 配置项 | 说明 |
|--------|------|
| `enabled` | 是否启用记忆搜索功能 |
| `extraPaths` | 额外搜索路径（除了默认 memory） |
| `provider` | 搜索提供者（local / remote） |
| `fallback` | QMD 失败时的降级策略 |
| `modelCacheDir` | 模型缓存目录 |

### 2.3 两层配置的关系

```
用户提问
    ↓
Agent.memorySearch (决定是否启用、调用方式)
    ↓
QMD 服务 (执行实际搜索)
    ↓
返回结果给 Agent
```

**关键区别：**
- `memory` 配置 = **QMD 服务本身**怎么工作（集合、索引、更新）
- `memorySearch` 配置 = **Agent**怎么使用 QMD（是否启用、额外路径）

**缺少 `memorySearch` 的后果：**
- Agent 可能根本不会调用 QMD
- 或者使用错误的搜索方式（如尝试远程 API）

---

## 3. 常用命令

### 3.1 查看状态

```bash
qmd status
```

### 3.2 管理集合

```bash
# 添加集合
qmd collection add ~/notes --name notes --mask "**/*.md"

# 列出所有集合
qmd collection list

# 删除集合
qmd collection remove notes
```

### 3.3 搜索文件

```bash
# 全文搜索（BM25）
qmd search "openclaw 配置"

# 语义搜索（向量相似度）
qmd vsearch "如何部署"

# 混合搜索（推荐）
qmd query "季度规划流程"

# 指定集合
qmd search "记忆" -c memory

# 限制结果数
qmd search "关键词" -n 10
```

### 3.4 生成嵌入

```bash
# 为新文件生成向量嵌入
qmd embed

# 强制重新生成
qmd embed -f
```

### 3.5 维护索引

```bash
# 更新所有集合索引
qmd update

# 清理缓存和孤立数据
qmd cleanup
```

---

## 4. 模型说明

### 4.1 GGUF 格式

QMD 使用 **GGUF**（GPT-Generated Unified Format）模型文件，这是 llama.cpp 项目的标准格式：

- **量化压缩**：减小模型体积，降低内存占用
- **后缀含义**：`Q8_0` = 8-bit 量化，`Q4_K_M` = 4-bit 量化
- **本地推理**：无需 GPU 也可运行（CPU 推理较慢）

### 4.2 模型分工

| 模型 | 作用 |
|------|------|
| **Embedding** | 将文本转换为向量（768 维） |
| **Query Expansion** | 扩展查询词，提高召回率 |
| **Reranker** | 对搜索结果重新排序 |

### 4.3 模型更新

模型文件缓存在 `~/.cache/qmd/models/`，如需更新：

```bash
# 删除旧模型，下次运行自动下载新版本
rm ~/.cache/qmd/models/*.gguf
qmd status
```

---

## 5. 常见问题

### 5.1 ENOTDIR 错误

**现象：**
```
qmd update failed: ENOTDIR: not a directory, open '/path/to/file.md'
```

**原因：** 集合配置冲突，多个集合路径重叠

**解决：**
1. 设置 `"includeDefaultMemory": false`
2. 确保 `paths` 之间不重叠（使用 `!path` 排除）
3. 删除索引重建：
   ```bash
   rm ~/.cache/qmd/index.sqlite
   openclaw gateway restart
   ```

### 5.2 ARM64 编译失败

**现象：** `node-llama-cpp` 编译报错

**解决：**
```bash
# 安装编译依赖
sudo apt-get install build-essential cmake python3

# 如有 CUDA，确保 CUDA 路径正确
export PATH="/usr/local/cuda/bin:$PATH"

# 重新安装
bun install -g https://github.com/tobi/qmd
```

### 5.3 模型下载慢/失败

**现象：** 首次运行卡在模型下载

**解决：**
- 使用代理或更换网络
- 手动下载模型放到 `~/.cache/qmd/models/`
- 检查 HuggingFace 镜像

### 5.4 搜索结果为空

**排查：**
```bash
# 1. 检查文件是否被索引
qmd ls <collection>

# 2. 检查索引是否最新
qmd status

# 3. 手动更新索引
qmd update

# 4. 重新生成嵌入
qmd embed -f
```

---

## 6. 独立使用（不依赖 OpenClaw）

QMD 是独立工具，可以直接使用：

```bash
# 创建索引配置
cat > ~/qmd-index.yml << 'EOF'
collections:
  notes:
    path: ~/notes
    mask: "**/*.md"
  docs:
    path: ~/Documents
    mask: "**/*.md"
EOF

# 运行 QMD
qmd --index ~/qmd-index.yml status
qmd --index ~/qmd-index.yml search "关键词"
```

---

## 7. 参考资源

| 资源 | 链接 |
|------|------|
| QMD GitHub | https://github.com/tobi/qmd |
| GGUF 格式 | https://github.com/ggerganov/ggml |
| OpenClaw 文档 | https://docs.openclaw.ai |

---

*报告生成时间: 2026-02-11 23:15 CST Asia/Shanghai*
